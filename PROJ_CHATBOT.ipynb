{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "27ca2491",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\The_C\\anaconda3\\envs\\nlp\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:523: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\Users\\The_C\\anaconda3\\envs\\nlp\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:524: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\Users\\The_C\\anaconda3\\envs\\nlp\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\Users\\The_C\\anaconda3\\envs\\nlp\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\Users\\The_C\\anaconda3\\envs\\nlp\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\Users\\The_C\\anaconda3\\envs\\nlp\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:532: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "import json ## for json file\n",
    "import string ## for string manipulation\n",
    "import random ## for choosing random from the dataset\n",
    "import nltk ## for preprocessing\n",
    "import numpy as np ##for mathmatical operations on array\n",
    "from tensorflow import keras ##for buliding the model for training\n",
    "from nltk.stem import WordNetLemmatizer ##for lemmatizing returning the word to its form\n",
    "from nltk.corpus import stopwords\n",
    "import tensorflow as tf ##for training\n",
    "from tensorflow.keras import Sequential ## used in model\n",
    "from tensorflow.keras.optimizers import SGD ##used in model \n",
    "from tensorflow.keras.layers import Dense,Dropout ## used in model\n",
    "import re\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40fa3a32",
   "metadata": {},
   "source": [
    "# Preprocessing the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "abd90288",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('C:\\\\Users\\\\The_C\\\\Downloads\\\\archive (2)\\\\intents.json','r')as f: ##open the json file\n",
    "    intents=json.load(f) ##read the json file for manipulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f5319956",
   "metadata": {},
   "outputs": [],
   "source": [
    "words=[] ##all words of the array patterns\n",
    "classes=[] ##tag (classes) of the dataset\n",
    "documents=[] ## patterns(input of the user) with its tag(classes)\n",
    "lemmatizer=WordNetLemmatizer()  ##lemmatizing : returning the words back to its basic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d2da9b4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "documents: [(['Hi'], 'greeting'), (['How', 'are', 'you', '?'], 'greeting'), (['Is', 'anyone', 'there', '?'], 'greeting'), (['Hello'], 'greeting'), (['Good', 'day'], 'greeting'), (['What', \"'s\", 'up'], 'greeting'), (['how', 'are', 'ya'], 'greeting'), (['heyy'], 'greeting'), (['whatsup'], 'greeting'), (['?', '?', '?', '?', '?', '?', '?', '?'], 'greeting'), (['cya'], 'goodbye'), (['see', 'you'], 'goodbye'), (['bye', 'bye'], 'goodbye'), (['See', 'you', 'later'], 'goodbye'), (['Goodbye'], 'goodbye'), (['I', 'am', 'Leaving'], 'goodbye'), (['Bye'], 'goodbye'), (['Have', 'a', 'Good', 'day'], 'goodbye'), (['talk', 'to', 'you', 'later'], 'goodbye'), (['ttyl'], 'goodbye'), (['i', 'got', 'to', 'go'], 'goodbye'), (['gtg'], 'goodbye'), (['what', 'is', 'the', 'name', 'of', 'your', 'developers'], 'creator'), (['what', 'is', 'the', 'name', 'of', 'your', 'creators'], 'creator'), (['what', 'is', 'the', 'name', 'of', 'the', 'developers'], 'creator'), (['what', 'is', 'the', 'name', 'of', 'the', 'creators'], 'creator'), (['who', 'created', 'you'], 'creator'), (['your', 'developers'], 'creator'), (['your', 'creators'], 'creator'), (['who', 'are', 'your', 'developers'], 'creator'), (['developers'], 'creator'), (['you', 'are', 'made', 'by'], 'creator'), (['you', 'are', 'made', 'by', 'whom'], 'creator'), (['who', 'created', 'you'], 'creator'), (['who', 'create', 'you'], 'creator'), (['creators'], 'creator'), (['who', 'made', 'you'], 'creator'), (['who', 'designed', 'you'], 'creator'), (['name'], 'name'), (['your', 'name'], 'name'), (['do', 'you', 'have', 'a', 'name'], 'name'), (['what', 'are', 'you', 'called'], 'name'), (['what', 'is', 'your', 'name'], 'name'), (['what', 'should', 'I', 'call', 'you'], 'name'), (['whats', 'your', 'name', '?'], 'name'), (['what', 'are', 'you'], 'name'), (['who', 'are', 'you'], 'name'), (['who', 'is', 'this'], 'name'), (['what', 'am', 'i', 'chatting', 'to'], 'name'), (['who', 'am', 'i', 'taking', 'to'], 'name'), (['what', 'are', 'you'], 'name'), (['timing', 'of', 'college'], 'hours'), (['what', 'is', 'college', 'timing'], 'hours'), (['working', 'days'], 'hours'), (['when', 'are', 'you', 'guys', 'open'], 'hours'), (['what', 'are', 'your', 'hours'], 'hours'), (['hours', 'of', 'operation'], 'hours'), (['when', 'is', 'the', 'college', 'open'], 'hours'), (['college', 'timing'], 'hours'), (['what', 'about', 'college', 'timing'], 'hours'), (['is', 'college', 'open', 'on', 'saturday'], 'hours'), (['tell', 'something', 'about', 'college', 'timing'], 'hours'), (['what', 'is', 'the', 'college', 'hours'], 'hours'), (['when', 'should', 'i', 'come', 'to', 'college'], 'hours'), (['when', 'should', 'i', 'attend', 'college'], 'hours'), (['what', 'is', 'my', 'college', 'time'], 'hours'), (['college', 'timing'], 'hours'), (['timing', 'college'], 'hours'), (['more', 'info'], 'number'), (['contact', 'info'], 'number'), (['how', 'to', 'contact', 'college'], 'number'), (['college', 'telephone', 'number'], 'number'), (['college', 'number'], 'number'), (['What', 'is', 'your', 'contact', 'no'], 'number'), (['Contact', 'number', '?'], 'number'), (['how', 'to', 'call', 'you'], 'number'), (['College', 'phone', 'no', '?'], 'number'), (['how', 'can', 'i', 'contact', 'you'], 'number'), (['Can', 'i', 'get', 'your', 'phone', 'number'], 'number'), (['how', 'can', 'i', 'call', 'you'], 'number'), (['phone', 'number'], 'number'), (['phone', 'no'], 'number'), (['call'], 'number'), (['list', 'of', 'courses'], 'course'), (['list', 'of', 'courses', 'offered'], 'course'), (['list', 'of', 'courses', 'offered', 'in'], 'course'), (['what', 'are', 'the', 'courses', 'offered', 'in', 'your', 'college', '?'], 'course'), (['courses', '?'], 'course'), (['courses', 'offered'], 'course'), (['courses', 'offered', 'in', '(', 'your', 'univrsity', '(', 'UNI', ')', 'name', ')'], 'course'), (['courses', 'you', 'offer'], 'course'), (['branches', '?'], 'course'), (['courses', 'available', 'at', 'UNI', '?'], 'course'), (['branches', 'available', 'at', 'your', 'college', '?'], 'course'), (['what', 'are', 'the', 'courses', 'in', 'UNI', '?'], 'course'), (['what', 'are', 'branches', 'in', 'UNI', '?'], 'course'), (['what', 'are', 'courses', 'in', 'UNI', '?'], 'course'), (['branches', 'available', 'in', 'UNI', '?'], 'course'), (['can', 'you', 'tell', 'me', 'the', 'courses', 'available', 'in', 'UNI', '?'], 'course'), (['can', 'you', 'tell', 'me', 'the', 'branches', 'available', 'in', 'UNI', '?'], 'course'), (['computer', 'engineering', '?'], 'course'), (['computer'], 'course'), (['Computer', 'engineering', '?'], 'course'), (['it'], 'course'), (['IT'], 'course'), (['Information', 'Technology'], 'course'), (['AI/Ml'], 'course'), (['Mechanical', 'engineering'], 'course'), (['Chemical', 'engineering'], 'course'), (['Civil', 'engineering'], 'course'), (['information', 'about', 'fee'], 'fees'), (['information', 'on', 'fee'], 'fees'), (['tell', 'me', 'the', 'fee'], 'fees'), (['college', 'fee'], 'fees'), (['fee', 'per', 'semester'], 'fees'), (['what', 'is', 'the', 'fee', 'of', 'each', 'semester'], 'fees'), (['what', 'is', 'the', 'fees', 'of', 'each', 'year'], 'fees'), (['what', 'is', 'fee'], 'fees'), (['what', 'is', 'the', 'fees'], 'fees'), (['how', 'much', 'is', 'the', 'fees'], 'fees'), (['fees', 'for', 'first', 'year'], 'fees'), (['fees'], 'fees'), (['about', 'the', 'fees'], 'fees'), (['tell', 'me', 'something', 'about', 'the', 'fees'], 'fees'), (['What', 'is', 'the', 'fees', 'of', 'hostel'], 'fees'), (['how', 'much', 'is', 'the', 'fees'], 'fees'), (['hostel', 'fees'], 'fees'), (['fees', 'for', 'AC', 'room'], 'fees'), (['fees', 'for', 'non-AC', 'room'], 'fees'), (['fees', 'for', 'Ac', 'room', 'for', 'girls'], 'fees'), (['fees', 'for', 'non-Ac', 'room', 'for', 'girls'], 'fees'), (['fees', 'for', 'Ac', 'room', 'for', 'boys'], 'fees'), (['fees', 'for', 'non-Ac', 'room', 'for', 'boys'], 'fees'), (['where', 'is', 'the', 'college', 'located'], 'location'), (['college', 'is', 'located', 'at'], 'location'), (['where', 'is', 'college'], 'location'), (['where', 'is', 'college', 'located'], 'location'), (['address', 'of', 'college'], 'location'), (['how', 'to', 'reach', 'college'], 'location'), (['college', 'location'], 'location'), (['college', 'address'], 'location'), (['wheres', 'the', 'college'], 'location'), (['how', 'can', 'I', 'reach', 'college'], 'location'), (['whats', 'is', 'the', 'college', 'address'], 'location'), (['what', 'is', 'the', 'address', 'of', 'college'], 'location'), (['address'], 'location'), (['location'], 'location'), (['hostel', 'facility'], 'hostel'), (['hostel', 'servive'], 'hostel'), (['hostel', 'location'], 'hostel'), (['hostel', 'address'], 'hostel'), (['hostel', 'facilities'], 'hostel'), (['hostel', 'fees'], 'hostel'), (['Does', 'college', 'provide', 'hostel'], 'hostel'), (['Is', 'there', 'any', 'hostel'], 'hostel'), (['Where', 'is', 'hostel'], 'hostel'), (['do', 'you', 'have', 'hostel'], 'hostel'), (['do', 'you', 'guys', 'have', 'hostel'], 'hostel'), (['hostel'], 'hostel'), (['hostel', 'capacity'], 'hostel'), (['what', 'is', 'the', 'hostel', 'fee'], 'hostel'), (['how', 'to', 'get', 'in', 'hostel'], 'hostel'), (['what', 'is', 'the', 'hostel', 'address'], 'hostel'), (['how', 'far', 'is', 'hostel', 'from', 'college'], 'hostel'), (['hostel', 'college', 'distance'], 'hostel'), (['where', 'is', 'the', 'hostel'], 'hostel'), (['how', 'big', 'is', 'the', 'hostel'], 'hostel'), (['distance', 'between', 'college', 'and', 'hostel'], 'hostel'), (['distance', 'between', 'hostel', 'and', 'college'], 'hostel'), (['events', 'organised'], 'event'), (['list', 'of', 'events'], 'event'), (['list', 'of', 'events', 'organised', 'in', 'college'], 'event'), (['list', 'of', 'events', 'conducted', 'in', 'college'], 'event'), (['What', 'events', 'are', 'conducted', 'in', 'college'], 'event'), (['Are', 'there', 'any', 'event', 'held', 'at', 'college'], 'event'), (['Events', '?'], 'event'), (['functions'], 'event'), (['what', 'are', 'the', 'events'], 'event'), (['tell', 'me', 'about', 'events'], 'event'), (['what', 'about', 'events'], 'event'), (['document', 'to', 'bring'], 'document'), (['documents', 'needed', 'for', 'admision'], 'document'), (['documents', 'needed', 'at', 'the', 'time', 'of', 'admission'], 'document'), (['documents', 'needed', 'during', 'admission'], 'document'), (['documents', 'required', 'for', 'admision'], 'document'), (['documents', 'required', 'at', 'the', 'time', 'of', 'admission'], 'document'), (['documents', 'required', 'during', 'admission'], 'document'), (['What', 'document', 'are', 'required', 'for', 'admission'], 'document'), (['Which', 'document', 'to', 'bring', 'for', 'admission'], 'document'), (['documents'], 'document'), (['what', 'documents', 'do', 'i', 'need'], 'document'), (['what', 'documents', 'do', 'I', 'need', 'for', 'admission'], 'document'), (['documents', 'needed'], 'document'), (['size', 'of', 'campus'], 'floors'), (['building', 'size'], 'floors'), (['How', 'many', 'floors', 'does', 'college', 'have'], 'floors'), (['floors', 'in', 'college'], 'floors'), (['floors', 'in', 'college'], 'floors'), (['how', 'tall', 'is', 'UNI', \"'s\", 'College', 'of', 'Engineering', 'college', 'building'], 'floors'), (['floors'], 'floors'), (['Syllabus', 'for', 'IT'], 'syllabus'), (['what', 'is', 'the', 'Information', 'Technology', 'syllabus'], 'syllabus'), (['syllabus'], 'syllabus'), (['timetable'], 'syllabus'), (['what', 'is', 'IT', 'syllabus'], 'syllabus'), (['syllabus'], 'syllabus'), (['What', 'is', 'next', 'lecture'], 'syllabus'), (['is', 'there', 'any', 'library'], 'library'), (['library', 'facility'], 'library'), (['library', 'facilities'], 'library'), (['do', 'you', 'have', 'library'], 'library'), (['does', 'the', 'college', 'have', 'library', 'facility'], 'library'), (['college', 'library'], 'library'), (['where', 'can', 'i', 'get', 'books'], 'library'), (['book', 'facility'], 'library'), (['Where', 'is', 'library'], 'library'), (['Library'], 'library'), (['Library', 'information'], 'library'), (['Library', 'books', 'information'], 'library'), (['Tell', 'me', 'about', 'library'], 'library'), (['how', 'many', 'libraries'], 'library'), (['how', 'is', 'college', 'infrastructure'], 'infrastructure'), (['infrastructure'], 'infrastructure'), (['college', 'infrastructure'], 'infrastructure'), (['food', 'facilities'], 'canteen'), (['canteen', 'facilities'], 'canteen'), (['canteen', 'facility'], 'canteen'), (['is', 'there', 'any', 'canteen'], 'canteen'), (['Is', 'there', 'a', 'cafetaria', 'in', 'college'], 'canteen'), (['Does', 'college', 'have', 'canteen'], 'canteen'), (['Where', 'is', 'canteen'], 'canteen'), (['where', 'is', 'cafetaria'], 'canteen'), (['canteen'], 'canteen'), (['Food'], 'canteen'), (['Cafetaria'], 'canteen'), (['food', 'menu'], 'menu'), (['food', 'in', 'canteen'], 'menu'), (['Whats', 'there', 'on', 'menu'], 'menu'), (['what', 'is', 'available', 'in', 'college', 'canteen'], 'menu'), (['what', 'foods', 'can', 'we', 'get', 'in', 'college', 'canteen'], 'menu'), (['food', 'variety'], 'menu'), (['What', 'is', 'there', 'to', 'eat', '?'], 'menu'), (['What', 'is', 'college', 'placement'], 'placement'), (['Which', 'companies', 'visit', 'in', 'college'], 'placement'), (['What', 'is', 'average', 'package'], 'placement'), (['companies', 'visit'], 'placement'), (['package'], 'placement'), (['About', 'placement'], 'placement'), (['placement'], 'placement'), (['recruitment'], 'placement'), (['companies'], 'placement'), (['Who', 'is', 'HOD'], 'ithod'), (['Where', 'is', 'HOD'], 'ithod'), (['it', 'hod'], 'ithod'), (['name', 'of', 'it', 'hod'], 'ithod'), (['Who', 'is', 'computer', 'HOD'], 'computerhod'), (['Where', 'is', 'computer', 'HOD'], 'computerhod'), (['computer', 'hod'], 'computerhod'), (['name', 'of', 'computer', 'hod'], 'computerhod'), (['Who', 'is', 'extc', 'HOD'], 'extchod'), (['Where', 'is', 'extc', 'HOD'], 'extchod'), (['extc', 'hod'], 'extchod'), (['name', 'of', 'extc', 'hod'], 'extchod'), (['what', 'is', 'the', 'name', 'of', 'principal'], 'principal'), (['whatv', 'is', 'the', 'principal', 'name'], 'principal'), (['principal', 'name'], 'principal'), (['Who', 'is', 'college', 'principal'], 'principal'), (['Where', 'is', 'principal', \"'s\", 'office'], 'principal'), (['principal'], 'principal'), (['name', 'of', 'principal'], 'principal'), (['exam', 'dates'], 'sem'), (['exam', 'schedule'], 'sem'), (['When', 'is', 'semester', 'exam'], 'sem'), (['Semester', 'exam', 'timetable'], 'sem'), (['sem'], 'sem'), (['semester'], 'sem'), (['exam'], 'sem'), (['when', 'is', 'exam'], 'sem'), (['exam', 'timetable'], 'sem'), (['exam', 'dates'], 'sem'), (['when', 'is', 'semester'], 'sem'), (['what', 'is', 'the', 'process', 'of', 'admission'], 'admission'), (['what', 'is', 'the', 'admission', 'process'], 'admission'), (['How', 'to', 'take', 'admission', 'in', 'your', 'college'], 'admission'), (['What', 'is', 'the', 'process', 'for', 'admission'], 'admission'), (['admission'], 'admission'), (['admission', 'process'], 'admission'), (['scholarship'], 'scholarship'), (['Is', 'scholarship', 'available'], 'scholarship'), (['scholarship', 'engineering'], 'scholarship'), (['scholarship', 'it'], 'scholarship'), (['scholarship', 'ce'], 'scholarship'), (['scholarship', 'mechanical'], 'scholarship'), (['scholarship', 'civil'], 'scholarship'), (['scholarship', 'chemical'], 'scholarship'), (['scholarship', 'for', 'AI/ML'], 'scholarship'), (['available', 'scholarships'], 'scholarship'), (['scholarship', 'for', 'computer', 'engineering'], 'scholarship'), (['scholarship', 'for', 'IT', 'engineering'], 'scholarship'), (['scholarship', 'for', 'mechanical', 'engineering'], 'scholarship'), (['scholarship', 'for', 'civil', 'engineering'], 'scholarship'), (['scholarship', 'for', 'chemical', 'engineering'], 'scholarship'), (['list', 'of', 'scholarship'], 'scholarship'), (['comps', 'scholarship'], 'scholarship'), (['IT', 'scholarship'], 'scholarship'), (['mechanical', 'scholarship'], 'scholarship'), (['civil', 'scholarship'], 'scholarship'), (['chemical', 'scholarship'], 'scholarship'), (['automobile', 'scholarship'], 'scholarship'), (['first', 'year', 'scholarship'], 'scholarship'), (['second', 'year', 'scholarship'], 'scholarship'), (['third', 'year', 'scholarship'], 'scholarship'), (['fourth', 'year', 'scholarship'], 'scholarship'), (['What', 'facilities', 'college', 'provide'], 'facilities'), (['College', 'facility'], 'facilities'), (['What', 'are', 'college', 'facilities'], 'facilities'), (['facilities'], 'facilities'), (['facilities', 'provided'], 'facilities'), (['max', 'number', 'of', 'students'], 'college intake'), (['number', 'of', 'seats', 'per', 'branch'], 'college intake'), (['number', 'of', 'seats', 'in', 'each', 'branch'], 'college intake'), (['maximum', 'number', 'of', 'seats'], 'college intake'), (['maximum', 'students', 'intake'], 'college intake'), (['What', 'is', 'college', 'intake'], 'college intake'), (['how', 'many', 'stundent', 'are', 'taken', 'in', 'each', 'branch'], 'college intake'), (['seat', 'allotment'], 'college intake'), (['seats'], 'college intake'), (['college', 'dress', 'code'], 'uniform'), (['college', 'dresscode'], 'uniform'), (['what', 'is', 'the', 'uniform'], 'uniform'), (['can', 'we', 'wear', 'casuals'], 'uniform'), (['Does', 'college', 'have', 'an', 'uniform'], 'uniform'), (['Is', 'there', 'any', 'uniform'], 'uniform'), (['uniform'], 'uniform'), (['what', 'about', 'uniform'], 'uniform'), (['do', 'we', 'have', 'to', 'wear', 'uniform'], 'uniform'), (['what', 'are', 'the', 'different', 'committe', 'in', 'college'], 'committee'), (['different', 'committee', 'in', 'college'], 'committee'), (['Are', 'there', 'any', 'committee', 'in', 'college'], 'committee'), (['Give', 'me', 'committee', 'details'], 'committee'), (['committee'], 'committee'), (['how', 'many', 'committee', 'are', 'there', 'in', 'college'], 'committee'), (['I', 'love', 'you'], 'random'), (['Will', 'you', 'marry', 'me'], 'random'), (['Do', 'you', 'love', 'me'], 'random'), (['fuck'], 'swear'), (['bitch'], 'swear'), (['shut', 'up'], 'swear'), (['hell'], 'swear'), (['stupid'], 'swear'), (['idiot'], 'swear'), (['dumb', 'ass'], 'swear'), (['asshole'], 'swear'), (['fucker'], 'swear'), (['holidays'], 'vacation'), (['when', 'will', 'semester', 'starts'], 'vacation'), (['when', 'will', 'semester', 'end'], 'vacation'), (['when', 'is', 'the', 'holidays'], 'vacation'), (['list', 'of', 'holidays'], 'vacation'), (['Holiday', 'in', 'these', 'year'], 'vacation'), (['holiday', 'list'], 'vacation'), (['about', 'vacations'], 'vacation'), (['about', 'holidays'], 'vacation'), (['When', 'is', 'vacation'], 'vacation'), (['When', 'is', 'holidays'], 'vacation'), (['how', 'long', 'will', 'be', 'the', 'vacation'], 'vacation'), (['sports', 'and', 'games'], 'sports'), (['give', 'sports', 'details'], 'sports'), (['sports', 'infrastructure'], 'sports'), (['sports', 'facilities'], 'sports'), (['information', 'about', 'sports'], 'sports'), (['Sports', 'activities'], 'sports'), (['please', 'provide', 'sports', 'and', 'games', 'information'], 'sports'), (['okk'], 'salutaion'), (['okie'], 'salutaion'), (['nice', 'work'], 'salutaion'), (['well', 'done'], 'salutaion'), (['good', 'job'], 'salutaion'), (['thanks', 'for', 'the', 'help'], 'salutaion'), (['Thank', 'You'], 'salutaion'), (['its', 'ok'], 'salutaion'), (['Thanks'], 'salutaion'), (['Good', 'work'], 'salutaion'), (['k'], 'salutaion'), (['ok'], 'salutaion'), (['okay'], 'salutaion'), (['what', 'can', 'you', 'do'], 'task'), (['what', 'are', 'the', 'thing', 'you', 'can', 'do'], 'task'), (['things', 'you', 'can', 'do'], 'task'), (['what', 'can', 'u', 'do', 'for', 'me'], 'task'), (['how', 'u', 'can', 'help', 'me'], 'task'), (['why', 'i', 'should', 'use', 'you'], 'task'), (['ragging'], 'ragging'), (['is', 'ragging', 'practice', 'active', 'in', 'college'], 'ragging'), (['does', 'college', 'have', 'any', 'antiragging', 'facility'], 'ragging'), (['is', 'there', 'any', 'ragging', 'cases'], 'ragging'), (['is', 'ragging', 'done', 'here'], 'ragging'), (['ragging', 'against'], 'ragging'), (['antiragging', 'facility'], 'ragging'), (['ragging', 'juniors'], 'ragging'), (['ragging', 'history'], 'ragging'), (['ragging', 'incidents'], 'ragging'), (['hod'], 'hod'), (['hod', 'name'], 'hod'), (['who', 'is', 'the', 'hod'], 'hod'), (['What', 'happens', 'to', 'water', 'in', 'very', 'high', 'degree', '?'], 'science'), (['exit'], 'exit'), (['call', 'my', 'freind'], 'call'), (['exit'], 'exit'), (['my', 'best', 'friend'], 'friend'), (['iam', 'sick'], 'sickness'), (['what', 'time', 'is', 'it'], 'date')]\n"
     ]
    }
   ],
   "source": [
    "for intent in intents['intents']:  ## for loop for entering the elements of dataset (enter the intents list) \n",
    "    for pattern in intent['patterns']: ## for loop for entering the elements of dataset (enter the patterns list which in the in intents list) and put is in a variable called intent\n",
    "        wordlist = nltk.word_tokenize(pattern) ## make each sentence in patterns a list of words and put in variable called wordlist\n",
    "        words.extend(wordlist)  ##extend the variable words each time putting wordlist list in the words list to make one array of all words in patterns dataset\n",
    "        documents.append((wordlist,intent['tag'])) ##assign each word in array patterns to its array tag\n",
    "        if intent['tag'] not in classes : \n",
    "                         classes.append(intent['tag']) ##assign each tag to variable classes for specifying each class\n",
    "\n",
    "words=[lemmatizer.lemmatize(word.lower()) for word in words if word not in string.punctuation and word not in stopwords.words('english') ] ##processing each word in words for lemmatization and removal of punctuation\n",
    "words = sorted(set(words)) #sorting alphabetical ascending and set for avoid repetition\n",
    "classes=sorted(set(classes)) #sorting alphabetical ascending and set for avoid repetition\n",
    "print(\"documents:\",documents)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb0006b3",
   "metadata": {},
   "source": [
    "# Creating the training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d0f4cde8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bow: [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "outputrow: [0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "training: [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0]\n",
      "words: [\"'s\", 'about', 'ac', 'active', 'activity', 'address', 'admision', 'admission', 'ai/ml', 'allotment', 'antiragging', 'anyone', 'are', 'as', 'asshole', 'attend', 'automobile', 'available', 'average', 'best', 'big', 'bitch', 'book', 'boy', 'branch', 'bring', 'building', 'bye', 'cafetaria', 'call', 'called', 'campus', 'can', 'canteen', 'capacity', 'case', 'casuals', 'ce', 'chatting', 'chemical', 'civil', 'code', 'college', 'come', 'committe', 'committee', 'comp', 'company', 'computer', 'conducted', 'contact', 'course', 'create', 'created', 'creator', 'cya', 'date', 'day', 'degree', 'designed', 'detail', 'developer', 'different', 'distance', 'do', 'document', 'doe', 'done', 'dress', 'dresscode', 'dumb', 'eat', 'end', 'engineering', 'event', 'exam', 'exit', 'extc', 'facility', 'far', 'fee', 'first', 'floor', 'food', 'fourth', 'freind', 'friend', 'fuck', 'fucker', 'function', 'game', 'get', 'girl', 'give', 'go', 'good', 'goodbye', 'got', 'gtg', 'guy', 'happens', 'have', 'held', 'hell', 'hello', 'help', 'heyy', 'hi', 'high', 'history', 'hod', 'holiday', 'hostel', 'hour', 'how', 'i', 'iam', 'idiot', 'incident', 'info', 'information', 'infrastructure', 'intake', 'is', 'it', 'job', 'junior', 'k', 'later', 'leaving', 'lecture', 'library', 'list', 'located', 'location', 'long', 'love', 'made', 'many', 'marry', 'max', 'maximum', 'mechanical', 'menu', 'much', 'name', 'need', 'needed', 'next', 'nice', 'non-ac', 'number', 'offer', 'offered', 'office', 'ok', 'okay', 'okie', 'okk', 'open', 'operation', 'organised', 'package', 'per', 'phone', 'placement', 'please', 'practice', 'principal', 'process', 'provide', 'provided', 'ragging', 'reach', 'recruitment', 'required', 'room', 'saturday', 'schedule', 'scholarship', 'seat', 'second', 'see', 'sem', 'semester', 'servive', 'shut', 'sick', 'size', 'something', 'sport', 'start', 'student', 'stundent', 'stupid', 'syllabus', 'take', 'taken', 'taking', 'talk', 'tall', 'technology', 'telephone', 'tell', 'thank', 'thanks', 'thing', 'third', 'time', 'timetable', 'timing', 'ttyl', 'u', 'uni', 'uniform', 'univrsity', 'use', 'vacation', 'variety', 'visit', 'water', 'wear', 'well', 'what', 'whats', 'whatsup', 'whatv', 'when', 'where', 'wheres', 'which', 'who', 'will', 'work', 'working', 'ya', 'year', 'you']\n"
     ]
    }
   ],
   "source": [
    "training=[] ## for collecting x-train and y-train \n",
    "outputempty=[0] * len(classes) ##for putting initiating y-train classes\n",
    "for document in documents: ##for loop for manipulating each word in each classes\n",
    "    bow=[] ## bag of words for training the model the patterns for each classes\n",
    "    wordpatterns=document[0] ##assign each word in patterns in specific class to variable\n",
    "    wordpatterns=[lemmatizer.lemmatize(word.lower()) for word in wordpatterns if  word not in stopwords.words('english') ] ##preproccessing\n",
    "    for word in words: ##for loop each 'pattern' word in the dataset \n",
    "        bow.append(1) if word in wordpatterns else bow.append(0) ## create bag of words for each 'pattern' in each classes 'tag'\n",
    "    outputrow=list(outputempty) \n",
    "    outputrow[classes.index(document[1])]=1 ## assign the specific 'tag' for the specific word in 'pattern'  \n",
    "    training.append(bow + outputrow) ## put each list of bag of words to its class\n",
    "random.shuffle(training) ##random the training for more model accuracy\n",
    "training=np.array(training) ##using np.array to manipulate elements in the training\n",
    "trainX=training[:,:len(words)] ##bow variable training patterns list for for x-train \n",
    "trainY=training[:,len(words):] ##outputrow variable training patterns for y-train\n",
    "\n",
    "print(\"bow:\",np.array(bow))\n",
    "print(\"outputrow:\",outputrow)\n",
    "print(\"training:\",training[0])\n",
    "print(\"words:\",words)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46a09a37",
   "metadata": {},
   "source": [
    "# Buliding the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "73b1b232",
   "metadata": {},
   "outputs": [],
   "source": [
    "model=tf.keras.Sequential()\n",
    "model.add(tf.keras.layers.Dense(128,input_shape=(len(trainX[0]),),activation='relu'))\n",
    "model.add(tf.keras.layers.Dropout(0.5))\n",
    "model.add(tf.keras.layers.Dense(64,activation='relu'))\n",
    "model.add(tf.keras.layers.Dense(len(trainY[0]),activation='softmax'))\n",
    "sgd=tf.keras.optimizers.SGD(0.01,momentum=0.9,nesterov=True)\n",
    "model.compile(loss='categorical_crossentropy',optimizer=sgd,metrics=['accuracy'])\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fb355ced",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/60\n",
      "412/412 [==============================] - 0s 467us/step - loss: 3.7236 - acc: 0.0631\n",
      "Epoch 2/60\n",
      "412/412 [==============================] - 0s 133us/step - loss: 3.4959 - acc: 0.1311\n",
      "Epoch 3/60\n",
      "412/412 [==============================] - 0s 171us/step - loss: 3.1564 - acc: 0.2160\n",
      "Epoch 4/60\n",
      "412/412 [==============================] - 0s 99us/step - loss: 2.7556 - acc: 0.3204\n",
      "Epoch 5/60\n",
      "412/412 [==============================] - 0s 171us/step - loss: 2.3955 - acc: 0.4199\n",
      "Epoch 6/60\n",
      "412/412 [==============================] - 0s 97us/step - loss: 2.1203 - acc: 0.4587\n",
      "Epoch 7/60\n",
      "412/412 [==============================] - 0s 165us/step - loss: 1.8057 - acc: 0.5777\n",
      "Epoch 8/60\n",
      "412/412 [==============================] - 0s 101us/step - loss: 1.4764 - acc: 0.6602\n",
      "Epoch 9/60\n",
      "412/412 [==============================] - 0s 161us/step - loss: 1.3138 - acc: 0.6917\n",
      "Epoch 10/60\n",
      "412/412 [==============================] - 0s 109us/step - loss: 1.0378 - acc: 0.7500\n",
      "Epoch 11/60\n",
      "412/412 [==============================] - 0s 161us/step - loss: 0.8624 - acc: 0.7985\n",
      "Epoch 12/60\n",
      "412/412 [==============================] - 0s 109us/step - loss: 0.7796 - acc: 0.8204\n",
      "Epoch 13/60\n",
      "412/412 [==============================] - 0s 152us/step - loss: 0.6978 - acc: 0.8447\n",
      "Epoch 14/60\n",
      "412/412 [==============================] - 0s 118us/step - loss: 0.5958 - acc: 0.8665\n",
      "Epoch 15/60\n",
      "412/412 [==============================] - 0s 166us/step - loss: 0.4817 - acc: 0.9005\n",
      "Epoch 16/60\n",
      "412/412 [==============================] - 0s 103us/step - loss: 0.4565 - acc: 0.8932\n",
      "Epoch 17/60\n",
      "412/412 [==============================] - 0s 159us/step - loss: 0.4170 - acc: 0.9102\n",
      "Epoch 18/60\n",
      "412/412 [==============================] - 0s 109us/step - loss: 0.4786 - acc: 0.8738\n",
      "Epoch 19/60\n",
      "412/412 [==============================] - 0s 164us/step - loss: 0.3417 - acc: 0.9248\n",
      "Epoch 20/60\n",
      "412/412 [==============================] - 0s 154us/step - loss: 0.3255 - acc: 0.9175\n",
      "Epoch 21/60\n",
      "412/412 [==============================] - 0s 146us/step - loss: 0.3124 - acc: 0.9223\n",
      "Epoch 22/60\n",
      "412/412 [==============================] - 0s 104us/step - loss: 0.2747 - acc: 0.9417\n",
      "Epoch 23/60\n",
      "412/412 [==============================] - 0s 186us/step - loss: 0.2109 - acc: 0.9563\n",
      "Epoch 24/60\n",
      "412/412 [==============================] - 0s 104us/step - loss: 0.2180 - acc: 0.9466\n",
      "Epoch 25/60\n",
      "412/412 [==============================] - 0s 166us/step - loss: 0.2010 - acc: 0.9539\n",
      "Epoch 26/60\n",
      "412/412 [==============================] - 0s 120us/step - loss: 0.1730 - acc: 0.9660\n",
      "Epoch 27/60\n",
      "412/412 [==============================] - 0s 180us/step - loss: 0.2028 - acc: 0.9515\n",
      "Epoch 28/60\n",
      "412/412 [==============================] - 0s 106us/step - loss: 0.1921 - acc: 0.9539\n",
      "Epoch 29/60\n",
      "412/412 [==============================] - 0s 175us/step - loss: 0.2130 - acc: 0.9539\n",
      "Epoch 30/60\n",
      "412/412 [==============================] - 0s 134us/step - loss: 0.1936 - acc: 0.9539\n",
      "Epoch 31/60\n",
      "412/412 [==============================] - 0s 112us/step - loss: 0.1533 - acc: 0.9660\n",
      "Epoch 32/60\n",
      "412/412 [==============================] - 0s 183us/step - loss: 0.1648 - acc: 0.9660\n",
      "Epoch 33/60\n",
      "412/412 [==============================] - 0s 101us/step - loss: 0.1608 - acc: 0.9612\n",
      "Epoch 34/60\n",
      "412/412 [==============================] - 0s 181us/step - loss: 0.1940 - acc: 0.9466\n",
      "Epoch 35/60\n",
      "412/412 [==============================] - 0s 104us/step - loss: 0.1467 - acc: 0.9612\n",
      "Epoch 36/60\n",
      "412/412 [==============================] - 0s 183us/step - loss: 0.1195 - acc: 0.9684\n",
      "Epoch 37/60\n",
      "412/412 [==============================] - 0s 101us/step - loss: 0.1259 - acc: 0.9660\n",
      "Epoch 38/60\n",
      "412/412 [==============================] - 0s 150us/step - loss: 0.1446 - acc: 0.9587\n",
      "Epoch 39/60\n",
      "412/412 [==============================] - 0s 180us/step - loss: 0.1213 - acc: 0.9684\n",
      "Epoch 40/60\n",
      "412/412 [==============================] - 0s 107us/step - loss: 0.1511 - acc: 0.9612\n",
      "Epoch 41/60\n",
      "412/412 [==============================] - 0s 169us/step - loss: 0.1261 - acc: 0.9709\n",
      "Epoch 42/60\n",
      "412/412 [==============================] - 0s 119us/step - loss: 0.1287 - acc: 0.9733\n",
      "Epoch 43/60\n",
      "412/412 [==============================] - 0s 166us/step - loss: 0.1148 - acc: 0.9709\n",
      "Epoch 44/60\n",
      "412/412 [==============================] - 0s 99us/step - loss: 0.1274 - acc: 0.9612\n",
      "Epoch 45/60\n",
      "412/412 [==============================] - 0s 166us/step - loss: 0.1082 - acc: 0.9757\n",
      "Epoch 46/60\n",
      "412/412 [==============================] - 0s 102us/step - loss: 0.1152 - acc: 0.9757\n",
      "Epoch 47/60\n",
      "412/412 [==============================] - 0s 164us/step - loss: 0.1480 - acc: 0.9515\n",
      "Epoch 48/60\n",
      "412/412 [==============================] - 0s 103us/step - loss: 0.1316 - acc: 0.9587\n",
      "Epoch 49/60\n",
      "412/412 [==============================] - 0s 175us/step - loss: 0.1049 - acc: 0.9709\n",
      "Epoch 50/60\n",
      "412/412 [==============================] - 0s 136us/step - loss: 0.1130 - acc: 0.9636\n",
      "Epoch 51/60\n",
      "412/412 [==============================] - 0s 107us/step - loss: 0.1035 - acc: 0.9709\n",
      "Epoch 52/60\n",
      "412/412 [==============================] - 0s 163us/step - loss: 0.1052 - acc: 0.9684\n",
      "Epoch 53/60\n",
      "412/412 [==============================] - 0s 106us/step - loss: 0.1066 - acc: 0.9709\n",
      "Epoch 54/60\n",
      "412/412 [==============================] - 0s 156us/step - loss: 0.0865 - acc: 0.9733\n",
      "Epoch 55/60\n",
      "412/412 [==============================] - 0s 118us/step - loss: 0.1068 - acc: 0.9709\n",
      "Epoch 56/60\n",
      "412/412 [==============================] - 0s 118us/step - loss: 0.1067 - acc: 0.9684\n",
      "Epoch 57/60\n",
      "412/412 [==============================] - 0s 145us/step - loss: 0.1056 - acc: 0.9757\n",
      "Epoch 58/60\n",
      "412/412 [==============================] - 0s 107us/step - loss: 0.0896 - acc: 0.9709\n",
      "Epoch 59/60\n",
      "412/412 [==============================] - 0s 143us/step - loss: 0.1026 - acc: 0.9684\n",
      "Epoch 60/60\n",
      "412/412 [==============================] - 0s 126us/step - loss: 0.0928 - acc: 0.9709\n",
      "executed\n"
     ]
    }
   ],
   "source": [
    "\n",
    "hist=model.fit(np.array(trainX),np.array(trainY),epochs=60,batch_size=5,verbose=1)\n",
    "##model.save('chatbot',hist)\n",
    "print(\"executed\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e5cbfe5",
   "metadata": {},
   "source": [
    "# Preprocessing user input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e0305caf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_up_sentence(sentence):\n",
    "    sentence_words=nltk.word_tokenize(sentence.lower())\n",
    "    sentence_words=[lemmatizer.lemmatize(word) for word in  sentence_words if word not in stopwords.words('english')]\n",
    "    return sentence_words\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2d0c773d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def bag_of_words(sentence):\n",
    "    sentence_words=clean_up_sentence(sentence)\n",
    "    bow=[0]*len(words)\n",
    "    for w in sentence_words:\n",
    "        for i,word in enumerate(words):\n",
    "            if word ==w:\n",
    "                bow[i]=1\n",
    "    return bow\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "572fa1d8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'tag': 'name', 'probability': '0.4871839'}]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def predict_class(sentence):\n",
    "    bow=bag_of_words(sentence)\n",
    "    res=model.predict(np.array([bow]))[0]\n",
    "    ERROR_THRESHOLD=0.25\n",
    "    results=[[i,r] for i,r in enumerate(res) if r>ERROR_THRESHOLD] ## i is the 'classes' ,r is the probability of the class  \n",
    "    results.sort(key=lambda x:x[1] ,reverse=True)\n",
    "    result_list=[]\n",
    "    for r in results:\n",
    "        result_list.append({'tag':classes[r[0]],'probability':str(r[1])})\n",
    "    return result_list\n",
    "predict_class(\"who are you\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5006e136",
   "metadata": {},
   "source": [
    "# Output "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bab85eab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bot is running!\n",
      "hi\n",
      "Hello!\n",
      "what time is it\n",
      "Its 12pm wednesday may 2023  \n",
      "iam sick\n",
      "iam calling the doctor\n"
     ]
    }
   ],
   "source": [
    "def get_responses(intents_list,intents_json):\n",
    "    list_of__intents=intents_json['intents']\n",
    "    tag=intents_list[0]['tag']\n",
    "    for i in  list_of__intents :\n",
    "        if i['tag']==tag:\n",
    "            result=random.choice(i['responses'])\n",
    "            break\n",
    "    return result\n",
    "\n",
    "print(\"bot is running!\")\n",
    "while True:\n",
    "    message=input(\"\")\n",
    "    x=re.findall('[0-9]+',message)\n",
    "    if x:\n",
    "        print(\"I dont understand.\")\n",
    "        continue\n",
    "    a=re.findall('[a-z]',message)\n",
    "    z=re.findall('[A-Z]',message)\n",
    "    y=re.findall('^\\s',message)\n",
    "    if y and not a and not z:\n",
    "        print(\"I dont understand.\")\n",
    "        continue\n",
    "    if message == \"\":\n",
    "        print(\"I dont understand.\")\n",
    "        continue\n",
    "    ints=predict_class(message)\n",
    "    res=get_responses(ints,intents)\n",
    "    print(res)\n",
    "    if message==\"bye\" or message==\"BYE\" or message==\"exit\" or message==\"EXIT\":\n",
    "        break"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
